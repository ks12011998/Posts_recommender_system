# -*- coding: utf-8 -*-
"""Social_Comment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/143hnoIeedh7MyZEoLbGKJgz_szVq1EtH
"""

#Importing the required libraries
import numpy as np
import pandas as pd

df1 = pd.read_csv('/content/drive/My Drive/Social_comment/Mldata/users.csv')
df2 = pd.read_csv('/content/drive/My Drive/Social_comment/Mldata/views.csv')

df1

df2

#Dataframe merging steps
df2
df2.rename(columns = {'user_id':'_id'}, inplace = True)

df = df1.merge(df2, on='_id')
df

df3 = pd.read_csv('/content/drive/My Drive/Social_comment/Mldata/posts.csv')
df3

df3.rename(columns = {'_id':'post_id'}, inplace = True) 
df3

final_df = df.merge(df3,on='post_id')
final_df

#Recommendations  based on title column only
#data cleaning steps
from html.parser import HTMLParser
html_parser = HTMLParser()
final_df['title'] = final_df['title'].apply(lambda x: html_parser.unescape(x))
import re
final_df['title']= final_df['title'].apply(lambda x: x.lower())

#Extracting only words from Service
final_df['title'] = final_df['title'].apply(lambda x: re.sub(r'#[\W]*',' ',x))

final_df["title"] = final_df['title'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))
final_df['title']

#More data clearning
Appostophes = {"'s":"is","'re":"are","s":" "}
final_df['title']
for i in range(len(final_df)):
  words =  final_df['title'][i]
  for word in words:
    if word == "'s":
      word= "is"
    elif word == "'re":
      word =  "are"
  final_df['title'][i] = words

final_df['title']

final_df.shape

#Applying tfidf vectorizer on the data

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel 

X = final_df['title']
tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3),max_features=None,strip_accents='unicode', stop_words='english')
tf_matrix = tf.fit_transform(final_df['title'])
# df_temp = pd.DataFrame(tf.transform(X).todense(),columns=tf.get_feature_names())

#Finding the cosine similarities
cosine_similarities = linear_kernel(tf_matrix, tf_matrix) 
results = {}
idx = 0
row = 0
count = 0
for idx, row in final_df.iterrows():
   similar_indices = cosine_similarities[idx-1].argsort()[:-100:-1] 
   similar_items = [(cosine_similarities[idx-1][i], final_df['_id'][i]) for i in similar_indices] 
   results[row['_id']] = similar_items[1:]

def item(_id):  
  return final_df.loc[final_df['_id'] == _id]['title'].tolist()[0].split(' - ')[0] 

def recommend(item_id, num):
    print("Recommending " + str(num) + " products similar to " + item(item_id) + "...")   
    print("-------")    
    recs = results[item_id][:num]   
    for rec in recs: 
       print("Recommended: " + item(rec[1]) + " (score:" +      str(rec[0]) + ")")

#Recommendation results
recommend(item_id='5d60098a653a331687083238', num=10)

recommend(item_id='5ecb979eeaff6b0c3a58a4f0', num=10)

final_df.isnull().sum().any

final_df = final_df.dropna(how='any')

#Recommendations based on category column only
final_df['category'].dtypes
final_df.isnull().sum().any

final_df.shape

final_df['category'] = final_df['category'].replace("|",' ')

final_df['category']

#Recommendations based on category column
#Data cleaning steps
from html.parser import HTMLParser
html_parser = HTMLParser()
final_df['category'] = final_df['category'].apply(lambda x: html_parser.unescape(x))
import re
final_df['category']= final_df['category'].apply(lambda x: x.lower())

#Extracting only words from Service
final_df['category'] = final_df['category'].apply(lambda x: re.sub(r'#[\W]*',' ',x))

final_df['category'] = final_df['category'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))
final_df['category']

Appostophes = {"'s":"is","'re":"are","s":" "}
final_df['category'] = final_df['category'].replace("s",' ')
final_df['category'] = final_df['category'].replace("'s",'is')
final_df['category'] = final_df['category'].replace("'re",'are')

final_df['category']
final_df = final_df.reset_index(drop=True)

#Applying tdidf on category column only
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel 
tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3),max_features=None,strip_accents='unicode', stop_words='english')
tf_matrix = tf.fit_transform(final_df['category'])
# df_temp = pd.DataFrame(tf.transform(X).todense(),columns=tf.get_feature_names())

#Finding cosine similarities
cosine_similarities = linear_kernel(tf_matrix, tf_matrix) 
results = {}
idx = 0
row = 0
count = 0
for idx, row in final_df.iterrows():
   similar_indices = cosine_similarities[idx].argsort()[:-100:-1] 
   similar_items = [(cosine_similarities[idx][i], final_df['_id'][i]) for i in similar_indices] 
   results[row['_id']] = similar_items[1:]

def item(_id):  
  return final_df.loc[final_df['_id'] == _id]['title'].tolist()[0].split(' - ')[0] 

def recommend(item_id, num):
    print("Recommending " + str(num) + " products similar to " + item(item_id) + "...")   
    print("-------")    
    recs = results[item_id][:num]   
    for rec in recs: 
       print("Recommended: " + item(rec[1]) + " (score:" +      str(rec[0]) + ")")

#Recommendations result
recommend(item_id='5d60098a653a331687083238', num=10)

#Now applying nlp on two columns category and title
#Since matrix of nlp on title is different from nlp on category column

#matrix based on title column
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel 
tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3),max_features=None,strip_accents='unicode', stop_words='english')
tf_title_matrix = tf.fit_transform(final_df['title'])
# df_temp = pd.DataFrame(tf.transform(X).todense(),columns=tf.get_feature_names())

tf_matrix 

tf1 = np.array(tf_matrix)
tf_title_matrix

tf1
tf2 = np.array(tf_title_matrix)
tf2

tf_final = np.vstack((tf1,tf2))
tf_final

tf3 = tf_final.flatten()
tf3

from scipy.sparse import hstack
merged_mat = hstack((tf_matrix, tf_title_matrix))

#Merged sparsed matrix
merged_mat

cosine_similarities = linear_kernel(merged_mat, merged_mat) 
results = {}
idx = 0
row = 0
count = 0
for idx, row in final_df.iterrows():
   similar_indices = cosine_similarities[idx].argsort()[:-100:-1] 
   similar_items = [(cosine_similarities[idx][i], final_df['_id'][i]) for i in similar_indices] 
   results[row['_id']] = similar_items[1:]

def item(_id):  
  return final_df.loc[final_df['_id'] == _id]['title'].tolist()[0].split(' - ')[0] 

def recommend(item_id, num):
    print("Recommending " + str(num) + " products similar to " + item(item_id) + "...")   
    print("-------")    
    recs = results[item_id][:num]   
    for rec in recs: 
       print("Recommended: " + item(rec[1]) + " (score:" +      str(rec[0]) + ")")

#@title Default title text
#Recommendation results based  on both the columns
recommend(item_id='5d60098a653a331687083238', num=10)

#We applied tfidf lets try count vectorizer on first,second and the on both the columns
import nltk
nltk.download('punkt')
from sklearn.feature_extraction.text import CountVectorizer
count_vectorizer = CountVectorizer(
    analyzer="word", tokenizer=nltk.word_tokenize,
    preprocessor=None, stop_words='english', max_features=None)

#On title column recommendations
bag_of_words_title = count_vectorizer.fit_transform(final_df['title'])


#Finding the cosine similarities
cosine_similarities = linear_kernel(bag_of_words_title,bag_of_words_title) 
results = {}
idx = 0
row = 0
count = 0
for idx, row in final_df.iterrows():
   similar_indices = cosine_similarities[idx-1].argsort()[:-100:-1] 
   similar_items = [(cosine_similarities[idx-1][i], final_df['_id'][i]) for i in similar_indices] 
   results[row['_id']] = similar_items[1:]

def item(_id):  
  return final_df.loc[final_df['_id'] == _id]['title'].tolist()[0].split(' - ')[0] 

def recommend(item_id, num):
    print("Recommending " + str(num) + " products similar to " + item(item_id) + "...")   
    print("-------")    
    recs = results[item_id][:num]   
    for rec in recs: 
       print("Recommended: " + item(rec[1]) + " (score:" +      str(rec[0]) + ")")

#Recommendations result based on title column using count vectorizer
recommend(item_id='5d60098a653a331687083238', num=10)

#count vectorizer based on category column only

bag_of_words_category = count_vectorizer.fit_transform(final_df['category'])

cosine_similarities = linear_kernel(bag_of_words_category,bag_of_words_category) 
results = {}
idx = 0
row = 0
count = 0
for idx, row in final_df.iterrows():
   similar_indices = cosine_similarities[idx-1].argsort()[:-100:-1] 
   similar_items = [(cosine_similarities[idx-1][i], final_df['_id'][i]) for i in similar_indices] 
   results[row['_id']] = similar_items[1:]

def item(_id):  
  return final_df.loc[final_df['_id'] == _id]['title'].tolist()[0].split(' - ')[0] 

def recommend(item_id, num):
    print("Recommending " + str(num) + "posts similar to " + item(item_id) + "...")   
    print("-------")    
    recs = results[item_id][:num]   
    for rec in recs: 
       print("Recommended: " + item(rec[1]) + " (score:" +      str(rec[0]) + ")")

#Recommendation results based on category column only
recommend(item_id='5d60098a653a331687083238', num=10)

#count vectorizer on both the columns
#count vectorizer based on category column only

cosine_similarities = linear_kernel(merged_mat,merged_mat) 
results = {}
idx = 0
row = 0
count = 0
for idx, row in final_df.iterrows():
   similar_indices = cosine_similarities[idx-1].argsort()[:-100:-1] 
   similar_items = [(cosine_similarities[idx-1][i], final_df['_id'][i]) for i in similar_indices] 
   results[row['_id']] = similar_items[1:]

def item(_id):  
  return final_df.loc[final_df['_id'] == _id]['title'].tolist()[0].split(' - ')[0] 

def recommend(item_id, num):
    print("Recommending " + str(num) + " posts similar to " + item(item_id) + "...")   
    print("-------")    
    recs = results[item_id][:num]   
    for rec in recs: 
       print("Recommended: " + item(rec[1]) + " (score:" +      str(rec[0]) + ")")

#Recommending posts similar to a given post
recommend(item_id='5d60098a653a331687083238', num=10)

#Recommending posts for a given user id

def item(_id):  
  return final_df.loc[final_df['_id'] == _id]['title'].tolist()[0].split(' - ')[0] 

def recommend(item_id, num):
    print("Recommending " + str(num) + " posts for a given user id " + item_id + "...")   
    print("-------")    
    recs = results[item_id][:num]   
    for rec in recs: 
       print("Recommended: " + item(rec[1]) + " (score:" +      str(rec[0]) + ")")

#Recommendations result
recommend(item_id='5d60098a653a331687083238', num=10)